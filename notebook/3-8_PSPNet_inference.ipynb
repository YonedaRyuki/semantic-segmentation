{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-9goa6c11EN"
   },
   "source": [
    "# 3.8 推論の実施\n",
    "\n",
    "- 本ファイルでは、学習させたPSPNetでセマンティックセグメンテーションを行います。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxBY25_q11EP"
   },
   "source": [
    "# 学習目標\n",
    "\n",
    "\n",
    "1.\tセマンティックセグメンテーションの推論を実装できるようになる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06-sVnl711EP"
   },
   "source": [
    "# 事前準備\n",
    "\n",
    "- 学習させた重みパラメータ「pspnet50_30.pth」をフォルダ「weights」に用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1356,
     "status": "ok",
     "timestamp": 1640183555731,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "MQZLWp2z11EP"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5xc59Hy11EQ"
   },
   "source": [
    "# ファイルパスリストを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1640183556844,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "nrIeUjrT2dQA"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640183557194,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "pY1kMuJM2g1e"
   },
   "outputs": [],
   "source": [
    "sys.path.append('../semantic_segmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15403,
     "status": "ok",
     "timestamp": 1640183572595,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "0LLXJ_0Y11EQ",
    "outputId": "79b8e545-8c22-408a-d9f6-11255034fb2c"
   },
   "outputs": [],
   "source": [
    "from utils.numpy_dataloader import make_datapath_list  #, DataTransform\n",
    "\n",
    "\n",
    "# ファイルパスリスト作成\n",
    "rootpath = \"../semantic_segmentation/data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "# 後ほどアノテーション画像のみを使用する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r9EOQOa11ER"
   },
   "source": [
    "# ネットワークを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1640183576912,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "hnpLot75gCBj",
    "outputId": "9eedd3db-5da3-46a0-ed76-e127a94bb0ea"
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "# from utils.pspnet import PSPNet\n",
    "# from torchsummary import summary\n",
    "# net = PSPNet(n_classes=2)\n",
    "# # net.to(\"cuda\")\n",
    "# # net150 = PSPNet(n_classes=150)\n",
    "# # net150.to(\"cuda\")\n",
    "\n",
    "# # 学習済みパラメータをロード\n",
    "# state_dict = torch.load(\"../semantic_segmentation/weights/pspnet50_500_1111_img200_batch16_net.pth\",\n",
    "#                         map_location={'cuda:0': 'cpu'})\n",
    "# net.load_state_dict(state_dict)\n",
    "\n",
    "# print('ネットワーク設定完了：学習済みの重みをロードしました')\n",
    "\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1640182798778,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "p-_c0stvgNgS"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# net = PSPNet(n_classes=2)\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkxhCXPD6pht"
   },
   "outputs": [],
   "source": [
    "# net150 = PSPNet(n_classes=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9980,
     "status": "ok",
     "timestamp": 1638954934626,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "aj6lBYE063ah",
    "outputId": "840c9190-7af5-4626-9970-1b9b1d8a2209"
   },
   "outputs": [],
   "source": [
    "# net150.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1638954934627,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "M8EPpc7qpucF",
    "outputId": "eb7ae0eb-d01d-45db-c54b-70a504e918cd"
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# net.to(\"cuda\")\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1638954934959,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "oZYN_D-igXmI",
    "outputId": "6d8b7ef9-6711-48e1-8883-d4a60f7c0399"
   },
   "outputs": [],
   "source": [
    "# summary(net,(1,200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1556,
     "status": "error",
     "timestamp": 1640182983678,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "z1k2OSIp11ER",
    "outputId": "b423ea7f-3528-4820-9a49-ef5c684b1688"
   },
   "outputs": [],
   "source": [
    "from utils.pspnet import PSPNet\n",
    "from torchsummary import summary\n",
    "# net = PSPNet(n_classes=2)\n",
    "net = PSPNet(n_classes=2)\n",
    "\n",
    "# 学習済みパラメータをロード\n",
    "state_dict = torch.load(\"../semantic_segmentation/weights/np_array_weight/300_net.pth\",\n",
    "                        map_location={'cuda:0': 'cpu'})\n",
    "#/content/drive/MyDrive/3_semantic_segmentation/weights/pspnet50_30_1231.pth このweightの出力は150　これが原因\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52fAsg3311ES"
   },
   "source": [
    "# 推論実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file_path = \"../semantic_segmentation/data/VOCdevkit/VOC2012/gray_cat_JPEGImages/2007_004856.jpg\"\n",
    "# img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "# img_width, img_height = img.size\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# # 2. 前処理クラスの作成\n",
    "# # color_mean = (0.485, 0.456, 0.406)\n",
    "# # color_std = (0.229, 0.224, 0.225)\n",
    "# color_mean = 0.5 #1ch\n",
    "# color_std = 0.2\n",
    "# transform = DataTransform(\n",
    "#     input_size=200, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "# # 3. 前処理\n",
    "# # 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "# anno_file_path = val_anno_list[0]\n",
    "# anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "# p_palette = anno_class_img.getpalette()\n",
    "# phase = \"val\"\n",
    "# img, anno_class_img = transform(phase, img, anno_class_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.cuda().type()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(data, size):\n",
    "    \"\"\"\n",
    "    sizeは、自由　　　　　　\n",
    "    今はy ,xは同じサイズだが、違うサイズにしたければ、タプルでsizeを入力するとよい\n",
    "    入力データ：（y, x, 2 or 3）\n",
    "    出力：（size ,size, 2 or 3）\n",
    "    \"\"\"\n",
    "#     cut_data = np.swapaxes(data, 0, 2)\n",
    "#     cut_data = np.swapaxes(cut_data, 0, 1)\n",
    "#     print(cut_data.shape)\n",
    "    cut_data = data[None,:,:].astype(np.float32)\n",
    "    cut_data = torch.from_numpy(cut_data)\n",
    "    cut_data = cut_data.unsqueeze(0)\n",
    "    resize_data = F.interpolate(cut_data, (size, size), mode='bilinear', align_corners=False)\n",
    "    resize_data = np.squeeze(resize_data.detach().numpy())\n",
    "\n",
    "#     resize_data_ = np.swapaxes(resize_data, 0, 1)\n",
    "#     resize_data_ = np.swapaxes(resize_data_, 1, 2)\n",
    "    return resize_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "arr_file_path = \"/home/filament/Downloads/semantic_segmentation/data/VOCdevkit/VOC2012/filament_taurus_datasets_grey_arcnorm_array/taurus_%s.npy\"%i\n",
    "image_file_path = \"/home/filament/Desktop/taurus_img/taurus_%s.jpg\"%i\n",
    "# img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "arr = np.load(arr_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,45):\n",
    "    fig,ax = plt.subplots(1,3)\n",
    "    # arr_file_path = \"/home/filament/Downloads/semantic_segmentation/data/VOCdevkit/VOC2012/filament_taurus_datasets_grey_arcnorm_array/taurus_%s.npy\"%i\n",
    "    arr_file_path = \"/home/filament/Downloads/semantic_segmentation/data/VOCdevkit/VOC2012/fil_norm_data/taurus_%s.npy\"%i\n",
    "    image_file_path = \"/home/filament/Desktop/taurus_img/taurus_%s.jpg\"%i\n",
    "    # img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    arr = np.load(arr_file_path)\n",
    "    arr_width, arr_height = arr.shape[1],arr.shape[0]\n",
    "    # arr = np.array(img)\n",
    "    ax[0].imshow(arr)\n",
    "    \n",
    "\n",
    "    arr = torch.from_numpy(resize(arr,475))\n",
    "    anno_file_path = val_anno_list[0]\n",
    "    anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "    p_palette = anno_class_img.getpalette()\n",
    "\n",
    "    net.eval()\n",
    "    x = arr.unsqueeze(0)# ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "    x = x.unsqueeze(0)\n",
    "    outputs = net(x)\n",
    "    y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "    y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "    y = np.argmax(y, axis=0)\n",
    "    anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "    anno_class_img = anno_class_img.resize((arr_height, arr_width), Image.NEAREST)\n",
    "    anno_class_img.putpalette(p_palette)\n",
    "    ax[1].imshow(anno_class_img)\n",
    "    \n",
    "\n",
    "    trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "    anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "    for x in range(arr_width):\n",
    "        for y in range(arr_height):\n",
    "            # 推論結果画像のピクセルデータを取得\n",
    "            pixel = anno_class_img.getpixel((x, y))\n",
    "            r, g, b, a = pixel\n",
    "\n",
    "            # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "            if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # それ以外の色は用意した画像にピクセルを書き込む\n",
    "                trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "                # 150は透過度の大きさを指定している\n",
    "\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "    ax[2].imshow(result)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_y = y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_y = np.argmax(num_y[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,3,figsize=(16,16))\n",
    "ax[0,0].imshow(arr)\n",
    "ax[0,1].imshow(outputs[0][0][1].detach().numpy())\n",
    "ax[0,2].imshow(outputs[0][0][0].detach().numpy())\n",
    "ax[1,0].imshow(arg_y)\n",
    "ax[1,1].imshow(anno_class_img)\n",
    "ax[1,2].imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arg_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anno_class_img = Image.fromarray(np.uint8(arg_y), mode=\"P\")\n",
    "# anno_class_img = anno_class_img.resize((arr_width, arr_height), Image.NEAREST)\n",
    "# anno_class_img.putpalette(p_palette)\n",
    "# plt.imshow(anno_class_img)\n",
    "# plt.show()\n",
    "trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "for x in range(arr_width):\n",
    "    for y in range(arr_height):\n",
    "        # 推論結果画像のピクセルデータを取得\n",
    "        pixel = anno_class_img.getpixel((x, y))\n",
    "        r, g, b, a = pixel\n",
    "\n",
    "        # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "        if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # それ以外の色は用意した画像にピクセルを書き込む\n",
    "            trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "            # 150は透過度の大きさを指定している\n",
    "\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(outputs[0][0][1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(arr)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_2 = tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "720*1079*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 元画像の表示\n",
    "# image_file_path = \"../semantic_segmentation/data/VOCdevkit/VOC2012/JPEGImages/2007_000392.jpg\"\n",
    "image_file_path = \"../neko_jpg/inu_1.jpg\"\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "img_width, img_height = img.size\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# 2. 前処理クラスの作成\n",
    "# color_mean = (0.485, 0.456, 0.406)\n",
    "# color_std = (0.229, 0.224, 0.225)\n",
    "color_mean = 0.5 #1ch\n",
    "color_std = 0.2\n",
    "transform = DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "# 3. 前処理\n",
    "# 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "anno_file_path = val_anno_list[0]\n",
    "anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "p_palette = anno_class_img.getpalette()\n",
    "phase = \"val\"\n",
    "img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "####################\n",
    "# img = img.cuda()\n",
    "# anno_class_img = anno_class_img.cuda()\n",
    "####################\n",
    "\n",
    "# 4. PSPNetで推論する\n",
    "net.eval()\n",
    "x = img.unsqueeze(0) # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "outputs = net(x)\n",
    "y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "\n",
    "#################\n",
    "# y = y.cpu()\n",
    "#################\n",
    "\n",
    "# 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "y = np.argmax(y, axis=0)\n",
    "anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "anno_class_img.putpalette(p_palette)\n",
    "plt.imshow(anno_class_img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6. 画像を透過させて重ねる\n",
    "trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "        # 推論結果画像のピクセルデータを取得\n",
    "        pixel = anno_class_img.getpixel((x, y))\n",
    "        r, g, b, a = pixel\n",
    "\n",
    "        # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "        if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # それ以外の色は用意した画像にピクセルを書き込む\n",
    "            trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "            # 150は透過度の大きさを指定している\n",
    "\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "executionInfo": {
     "elapsed": 5823,
     "status": "ok",
     "timestamp": 1640183595631,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "klnIZtsj11ES",
    "outputId": "f999bf99-75f5-46bc-b251-1001b183bb6f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. 元画像の表示\n",
    "image_file_path = \"../itijitekinayatu/orionKL_1 (1).jpg\"\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "img_width, img_height = img.size\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. 前処理クラスの作成\n",
    "# color_mean = (0.485, 0.456, 0.406)\n",
    "# color_std = (0.229, 0.224, 0.225)\n",
    "color_mean = 0.5 #1ch\n",
    "color_std = 0.2\n",
    "transform = DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "# 3. 前処理\n",
    "# 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "anno_file_path = val_anno_list[0]\n",
    "anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "p_palette = anno_class_img.getpalette()\n",
    "phase = \"val\"\n",
    "img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "####################\n",
    "# img = img.cuda()\n",
    "# anno_class_img = anno_class_img.cuda()\n",
    "####################\n",
    "\n",
    "# 4. PSPNetで推論する\n",
    "net.eval()\n",
    "x = img.unsqueeze(0) # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "outputs = net(x)\n",
    "y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "\n",
    "#################\n",
    "# y = y.cpu()\n",
    "#################\n",
    "\n",
    "# 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "y = np.argmax(y, axis=0)\n",
    "anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "anno_class_img.putpalette(p_palette)\n",
    "plt.imshow(anno_class_img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6. 画像を透過させて重ねる\n",
    "trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "        # 推論結果画像のピクセルデータを取得\n",
    "        pixel = anno_class_img.getpixel((x, y))\n",
    "        r, g, b, a = pixel\n",
    "\n",
    "        # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "        if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # それ以外の色は用意した画像にピクセルを書き込む\n",
    "            trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "            # 150は透過度の大きさを指定している\n",
    "\n",
    "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = \"../semantic_segmentation/data/VOCdevkit/VOC2012/filament_taurus_datasets_grey/taurus_\"+str(1)+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path.split(\"/\")[6].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    # 1. 元画像の表示\n",
    "    image_file_path = \"../semantic_segmentation/data/VOCdevkit/VOC2012/filament_taurus_datasets_grey/taurus_\"+str(i+1)+\".jpg\"\n",
    "    fname = image_file_path.split(\"/\")[6].split(\".\")[0]\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    img_width, img_height = img.size\n",
    "    plt.imshow(img)\n",
    "    plt.imsave(\"../semantic_segmentation/inference/original/\" + fname + \".jpg\",img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 2. 前処理クラスの作成\n",
    "    # color_mean = (0.485, 0.456, 0.406)\n",
    "    # color_std = (0.229, 0.224, 0.225)\n",
    "    color_mean = 0.5 #1ch\n",
    "    color_std = 0.2\n",
    "    transform = DataTransform(\n",
    "        input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "    # 3. 前処理\n",
    "    # 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "    anno_file_path = val_anno_list[0]\n",
    "    anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "    p_palette = anno_class_img.getpalette()\n",
    "    phase = \"val\"\n",
    "    img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "    ####################\n",
    "    # img = img.cuda()\n",
    "    # anno_class_img = anno_class_img.cuda()\n",
    "    ####################\n",
    "\n",
    "    # 4. PSPNetで推論する\n",
    "    net.eval()\n",
    "    x = img.unsqueeze(0) # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "    outputs = net(x)\n",
    "    y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "\n",
    "    #################\n",
    "    # y = y.cpu()\n",
    "    #################\n",
    "\n",
    "    # 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "    y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "    y = np.argmax(y, axis=0)\n",
    "    anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "    anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "    anno_class_img.putpalette(p_palette)\n",
    "    plt.imshow(anno_class_img)\n",
    "    anno_class_img.save(\"../semantic_segmentation/inference/inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 6. 画像を透過させて重ねる\n",
    "    trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "    anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "    for x in range(img_width):\n",
    "        for y in range(img_height):\n",
    "            # 推論結果画像のピクセルデータを取得\n",
    "            pixel = anno_class_img.getpixel((x, y))\n",
    "            r, g, b, a = pixel\n",
    "\n",
    "            # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "            if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # それ以外の色は用意した画像にピクセルを書き込む\n",
    "                trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "                # 150は透過度の大きさを指定している\n",
    "\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "    plt.imshow(result)\n",
    "    result.save(\"../semantic_segmentation/inference/orginal_inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = glob.glob(\"../semantic_segmentation/test/test_val/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath[9].split(\"/\")[4].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = glob.glob(\"../semantic_segmentation/test/test_val/*.jpg\")\n",
    "\n",
    "\n",
    "for path in fpath:\n",
    "    # 1. 元画像の表示\n",
    "    image_file_path = path\n",
    "    fname = image_file_path.split(\"/\")[4].split(\".\")[0]\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    img_width, img_height = img.size\n",
    "    plt.imshow(img)\n",
    "    plt.imsave(\"../semantic_segmentation/inference/original/\" + fname + \".jpg\",img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 2. 前処理クラスの作成\n",
    "    # color_mean = (0.485, 0.456, 0.406)\n",
    "    # color_std = (0.229, 0.224, 0.225)\n",
    "    color_mean = 0.5 #1ch\n",
    "    color_std = 0.2\n",
    "    transform = DataTransform(\n",
    "        input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "    # 3. 前処理\n",
    "    # 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "    anno_file_path = val_anno_list[0]\n",
    "    anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "    p_palette = anno_class_img.getpalette()\n",
    "    phase = \"val\"\n",
    "    img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "    ####################\n",
    "    # img = img.cuda()\n",
    "    # anno_class_img = anno_class_img.cuda()\n",
    "    ####################\n",
    "\n",
    "    # 4. PSPNetで推論する\n",
    "    net.eval()\n",
    "    x = img.unsqueeze(0) # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "    outputs = net(x)\n",
    "    y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "\n",
    "    #################\n",
    "    # y = y.cpu()\n",
    "    #################\n",
    "\n",
    "    # 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "    y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "    y = np.argmax(y, axis=0)\n",
    "    anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "    anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "    anno_class_img.putpalette(p_palette)\n",
    "    plt.imshow(anno_class_img)\n",
    "    anno_class_img.save(\"../semantic_segmentation/inference/inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 6. 画像を透過させて重ねる\n",
    "    trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "    anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "    for x in range(img_width):\n",
    "        for y in range(img_height):\n",
    "            # 推論結果画像のピクセルデータを取得\n",
    "            pixel = anno_class_img.getpixel((x, y))\n",
    "            r, g, b, a = pixel\n",
    "\n",
    "            # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "            if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # それ以外の色は用意した画像にピクセルを書き込む\n",
    "                trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "                # 150は透過度の大きさを指定している\n",
    "\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "    plt.imshow(result)\n",
    "    result.save(\"../semantic_segmentation/inference/orginal_inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,19):\n",
    "    # 1. 元画像の表示\n",
    "    image_file_path = \"../semantic_segmentation/data/VOCdevkit/VOC2012/filament_taurus_datasets_grey/taurus_\"+str(i+1)+\".jpg\"\n",
    "    fname = image_file_path.split(\"/\")[6].split(\".\")[0]\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    img_width, img_height = img.size\n",
    "    plt.imshow(img)\n",
    "    plt.imsave(\"../semantic_segmentation/inference/original/\" + fname + \".jpg\",img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 2. 前処理クラスの作成\n",
    "    # color_mean = (0.485, 0.456, 0.406)\n",
    "    # color_std = (0.229, 0.224, 0.225)\n",
    "    color_mean = 0.5 #1ch\n",
    "    color_std = 0.2\n",
    "    transform = DataTransform(\n",
    "        input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "    # 3. 前処理\n",
    "    # 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "    anno_file_path = val_anno_list[0]\n",
    "    anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "    p_palette = anno_class_img.getpalette()\n",
    "    phase = \"val\"\n",
    "    img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "    ####################\n",
    "    # img = img.cuda()\n",
    "    # anno_class_img = anno_class_img.cuda()\n",
    "    ####################\n",
    "\n",
    "    # 4. PSPNetで推論する\n",
    "    net.eval()\n",
    "    x = img.unsqueeze(0) # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "    outputs = net(x)\n",
    "    y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "\n",
    "\n",
    "    #################\n",
    "    # y = y.cpu()\n",
    "    #################\n",
    "\n",
    "    # 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "    y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "    y = np.argmax(y, axis=0)\n",
    "    anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "    anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "    anno_class_img.putpalette(p_palette)\n",
    "    plt.imshow(anno_class_img)\n",
    "    anno_class_img.save(\"../semantic_segmentation/inference/inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 6. 画像を透過させて重ねる\n",
    "    trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "    anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "    for x in range(img_width):\n",
    "        for y in range(img_height):\n",
    "            # 推論結果画像のピクセルデータを取得\n",
    "            pixel = anno_class_img.getpixel((x, y))\n",
    "            r, g, b, a = pixel\n",
    "\n",
    "            # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "            if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # それ以外の色は用意した画像にピクセルを書き込む\n",
    "                trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "                # 150は透過度の大きさを指定している\n",
    "\n",
    "    img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "    result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "    plt.imshow(result)\n",
    "    result.save(\"../semantic_segmentation/inference/orginal_inference/\" + fname + \".png\")\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1640183597831,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "8WXkBiEhX-XG"
   },
   "outputs": [],
   "source": [
    "def Segmentation(path):\n",
    "  # 1. 元画像の表示\n",
    "  image_file_path = path\n",
    "  fname = path.split(\"/\")[6].split(\".\")[0]\n",
    "  img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "  img_width, img_height = img.size\n",
    "  plt.imshow(img)\n",
    "  img.save(\"../semantic_segmentation/inference/original/\" + fname + \".jpg\")\n",
    "  plt.show()\n",
    "\n",
    "  # 2. 前処理クラスの作成\n",
    "  # color_mean = (0.485, 0.456, 0.406)\n",
    "  # color_std = (0.229, 0.224, 0.225)\n",
    "  color_mean = 0.5 #1ch\n",
    "  color_std = 0.2\n",
    "  transform = DataTransform(\n",
    "      input_size=475, color_mean=color_mean, color_std=color_std)\n",
    "\n",
    "  # 3. 前処理\n",
    "  # 適当なアノテーション画像を用意し、さらにカラーパレットの情報を抜き出す\n",
    "  anno_file_path = val_anno_list[0]\n",
    "  anno_class_img = Image.open(anno_file_path)   # [高さ][幅]\n",
    "  p_palette = anno_class_img.getpalette()\n",
    "  phase = \"val\"\n",
    "  img, anno_class_img = transform(phase, img, anno_class_img)\n",
    "  #################\n",
    "  # img = img.cuda()\n",
    "  # anno_class_img = anno_class_img.cuda()\n",
    "  #################\n",
    "\n",
    "\n",
    "  # 4. PSPNetで推論する\n",
    "  net.eval()\n",
    "  x = img.unsqueeze(0)  # ミニバッチ化：torch.Size([1, 3, 475, 475])\n",
    "  outputs = net(x)\n",
    "  y = outputs[0]  # AuxLoss側は無視 yのサイズはtorch.Size([1, 21, 475, 475])\n",
    "  ###################\n",
    "  # y = y.cpu()\n",
    "  ###################\n",
    "\n",
    "\n",
    "\n",
    "  # 5. PSPNetの出力から最大クラスを求め、カラーパレット形式にし、画像サイズを元に戻す\n",
    "  y = y[0].detach().numpy()  # y：torch.Size([1, 21, 475, 475])\n",
    "  y = np.argmax(y, axis=0)\n",
    "  anno_class_img = Image.fromarray(np.uint8(y), mode=\"P\")\n",
    "  anno_class_img = anno_class_img.resize((img_width, img_height), Image.NEAREST)\n",
    "  anno_class_img.putpalette(p_palette)\n",
    "  plt.imshow(anno_class_img)\n",
    "  anno_class_img.save(\"../semantic_segmentation/inference/inference/\" + fname + \".png\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "  # 6. 画像を透過させて重ねる\n",
    "  trans_img = Image.new('RGBA', anno_class_img.size, (0, 0, 0, 0))\n",
    "  anno_class_img = anno_class_img.convert('RGBA')  # カラーパレット形式をRGBAに変換\n",
    "\n",
    "  for x in range(img_width):\n",
    "      for y in range(img_height):\n",
    "          # 推論結果画像のピクセルデータを取得\n",
    "          pixel = anno_class_img.getpixel((x, y))\n",
    "          r, g, b, a = pixel\n",
    "\n",
    "          # (0, 0, 0)の背景ならそのままにして透過させる\n",
    "          if pixel[0] == 0 and pixel[1] == 0 and pixel[2] == 0:\n",
    "              continue\n",
    "          else:\n",
    "              # それ以外の色は用意した画像にピクセルを書き込む\n",
    "              trans_img.putpixel((x, y), (r, g, b, 150))\n",
    "              # 150は透過度の大きさを指定している\n",
    "\n",
    "  img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
    "  result = Image.alpha_composite(img.convert('RGBA'), trans_img)\n",
    "  plt.imshow(result)\n",
    "  result.save(\"../semantic_segmentation/inference/orginal_inference/\" + fname + \".png\")\n",
    "  plt.show()\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1640183608600,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "tf5O0u2IYqE-",
    "outputId": "85c2b4d3-f8c3-472d-a415-f2400569fb4c"
   },
   "outputs": [],
   "source": [
    "val_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1LgFHc-SvG6MPDZGtMHrRoC_e4ZekgC9V"
    },
    "executionInfo": {
     "elapsed": 467118,
     "status": "ok",
     "timestamp": 1640184076626,
     "user": {
      "displayName": "龍",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10936710371482780121"
     },
     "user_tz": -540
    },
    "id": "FAlMFvUfY5rY",
    "outputId": "1da7611f-8e51-4cd4-d554-c8c8b624ed6e"
   },
   "outputs": [],
   "source": [
    "for i in val_img_list:\n",
    "  Segmentation(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJbtuPcw11ET"
   },
   "source": [
    "以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgcEBrpNz2x6"
   },
   "outputs": [],
   "source": [
    "for i in train_img_list:\n",
    "  Segmentation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3-8_PSPNet_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
